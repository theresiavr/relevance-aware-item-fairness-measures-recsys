{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.evaluator.evaluator import Evaluator\n",
    "    \n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert most fair and relevant (total $km$ items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_items_not_in_rec(u, incoming_k_items, curr_rec):\n",
    "    mask = ~torch.isin(incoming_k_items[u],curr_rec[u])\n",
    "    return incoming_k_items[u][mask]\n",
    "\n",
    "def get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec):\n",
    "    mask = ~torch.isin(all_item_id, curr_rec[u])\n",
    "    item_not_in_rec = all_item_id[mask]\n",
    "    \n",
    "    mask_rel_not_in_rec = ~torch.isin(item_not_in_rec, rel_not_in_rec[u])\n",
    "    remaining_items = item_not_in_rec[mask_rel_not_in_rec]\n",
    "    return remaining_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "path = \"artificial_insertion_extra\"\n",
    "\n",
    "for num_user in [\n",
    "   1000,  \n",
    "]:\n",
    "\n",
    "    num_item = (num_user * k) \n",
    "    all_item_id = torch.arange(num_item) + 1\n",
    "\n",
    "    print(f\"There are {num_user} users, {num_item} items, and k={k}\")\n",
    "\n",
    "    #initialize user-k recommendation matrix by recommending the same k items to all users\n",
    "    same_k_items = np.arange(k)+1 #item index starts from 1\n",
    "    curr_rec = np.tile(same_k_items, (num_user,1))\n",
    "    curr_rec = torch.Tensor(curr_rec).int()\n",
    "\n",
    "    incoming_k_items = np.arange(num_item).reshape(num_user,k) + 1\n",
    "    incoming_k_items = torch.Tensor(incoming_k_items).int()\n",
    "\n",
    "    #initialize user-item_at_k relevance matrix (all irrelevant)\n",
    "    curr_rel = torch.zeros(num_user,k+1,dtype=torch.int32) #+1 because recbole saves number of rel items at the last column\n",
    "    curr_rel[0, :-1] = 1 #first user already has relevant items\n",
    "    curr_rel[:,-1] = k #each user has exactly k relevant items\n",
    "\n",
    "    incoming_k_relevance = torch.ones(num_user,k)\n",
    "\n",
    "    #take struct from a dataset\n",
    "    dataset = \"Amazon-lb\" \n",
    "    model_name = \"Pop\"\n",
    "    list_file = os.listdir(\"../struct/\")\n",
    "    file_for_dataset = [x for x in list_file if dataset in x]\n",
    "    assert len(file_for_dataset) == 1\n",
    "\n",
    "    with open(\"../struct/\"+file_for_dataset[0],\"rb\") as f:\n",
    "        struct = pickle.load(f)\n",
    "\n",
    "    config = Config(\n",
    "                    model=model_name, \n",
    "                    dataset=dataset, \n",
    "                    config_file_list=[\"../RecBole/recbole/properties/overall.yaml\"],\n",
    "                    config_dict={\n",
    "                        \"topk\":k,\n",
    "                        \"metrics\":[\n",
    "                                \"FixedIAAinsert\",\n",
    "                                \"FixedIFDrerank\",\n",
    "                                \"FixedIIF\",\n",
    "                                ]}\n",
    "                                )\n",
    "\n",
    "    evaluator = Evaluator(config)\n",
    "    struct.set(\"data.num_items\", num_item+1) #because -1 in metrics.py\n",
    "    struct.set(\"rec.items\", curr_rec)\n",
    "    struct.set(\"rec.topk\", curr_rel)\n",
    "    struct.set(\"rec.score\",torch.empty((num_user, num_item+1))) #needed for FixedIAAinsert, +1 to add a dummy col for pred_rel (pred_rel only taken from 1: onwards)\n",
    "    struct.set(\"data.pos_items\", incoming_k_items.numpy()) #incoming items are also the only relevant items, but numpy datatype\n",
    "    struct.set(\"data.name\", \"artificial\") \n",
    "    \n",
    "    rel_not_in_rec = [get_rel_items_not_in_rec(u, incoming_k_items, curr_rec) for u, _ in enumerate(incoming_k_items)]\n",
    "    remaining_items = [get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec) for u, _ in enumerate(curr_rec)]\n",
    "    full_rec_mat = torch.stack([torch.cat([curr_rec[u],remaining_items[u],rel_not_in_rec[u]]) for u, _ in enumerate(curr_rec)])\n",
    "    struct.set(\"rec.all_items\", full_rec_mat)\n",
    "\n",
    "    insertion_result = dict()\n",
    "    result = evaluator.evaluate(struct)\n",
    "    insertion_result[\"0\"] =  result\n",
    "    with open(f'{path}/fair_user_{str(num_user).zfill(4)}_exact_km_0.pickle', 'wb') as f:\n",
    "        pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    for pos_rank in range(k-1,-1, -1):\n",
    "        print(f\"Inserting fair and rel items for all users at {pos_rank}\")\n",
    "        curr_rec[:,pos_rank] = incoming_k_items[:,pos_rank]\n",
    "        curr_rel[:,pos_rank] = incoming_k_relevance[:,pos_rank]\n",
    "\n",
    "        struct.set(\"rec.items\", curr_rec)\n",
    "        struct.set(\"rec.topk\", curr_rel)\n",
    "\n",
    "        #for IAA and IFD that need full ranking\n",
    "        rel_not_in_rec = [get_rel_items_not_in_rec(u, incoming_k_items, curr_rec) for u, _ in enumerate(incoming_k_items)]\n",
    "        remaining_items = [get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec) for u, _ in enumerate(curr_rec)]\n",
    "        full_rec_mat = torch.stack([torch.cat([curr_rec[u],remaining_items[u],rel_not_in_rec[u]]) for u, _ in enumerate(curr_rec)])\n",
    "        struct.set(\"rec.all_items\", full_rec_mat)\n",
    "        print(full_rec_mat)\n",
    "  \n",
    "        start_time = time.time()\n",
    "        result = evaluator.evaluate(struct)\n",
    "        print(result)\n",
    "        print(\"total time taken: \", time.time() - start_time)\n",
    "        \n",
    "        insertion_result[f\"{k-pos_rank}\"] = result\n",
    "\n",
    "        #dump/save per pos_rank\n",
    "        with open(f'{path}/fair_user_{str(num_user).zfill(4)}_exact_km_{k-pos_rank}.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(f'{path}/fair_user_{str(num_user).zfill(4)}_exact_km.pickle', 'wb') as f:\n",
    "        pickle.dump(insertion_result, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustextend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
