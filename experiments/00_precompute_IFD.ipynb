{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precomputing $IFD_\\times$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import builtins\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"precomputeIFD\"\n",
    "best_struct_path = \"../cluster/best_struct\"\n",
    "\n",
    "def print(*args, **kwargs):\n",
    "    with open(f\"{path}/log_{dataset}.txt\", 'a+') as f:\n",
    "        return builtins.print(*args, file=f, **kwargs)\n",
    "    \n",
    "def compute_IFD_mul(ranks, cut_off=10):\n",
    "    num_item = len(ranks)\n",
    "    pos_index = np.arange(num_item)+1\n",
    "    dcg_weight =  1/ np.log2(pos_index+1)\n",
    "    if cut_off:\n",
    "        dcg_weight[cut_off:] = 0\n",
    "\n",
    "    ranks = np.asarray(ranks)\n",
    "    to_input_to_pairwise = (ranks * dcg_weight ).reshape(-1,1)\n",
    "    IFD_mul_pdist = pdist(to_input_to_pairwise, 'sqeuclidean')\n",
    "    IFD_mul = IFD_mul_pdist.mean()\n",
    "    return IFD_mul\n",
    "\n",
    "def precompute_max_IFD_mul(cut_off, num_items, num_rel_u, prev_rel_u, prev_strategy):\n",
    "    num_non_rel = num_items - num_rel_u\n",
    "    place_all_top = tuple([1]*num_rel_u + [0]*num_non_rel)\n",
    "\n",
    "    #x-y strategy\n",
    "    _, bottom = prev_strategy\n",
    "    if bottom != 0:\n",
    "        bottom = bottom + num_rel_u - prev_rel_u\n",
    "    else:\n",
    "        bottom = 1\n",
    "    top = num_rel_u - bottom\n",
    "\n",
    "    assert top + bottom == num_rel_u\n",
    "    place_x_y = tuple([1]*top + [0]*num_non_rel + [1]*bottom)\n",
    "\n",
    "    IFD_place_all_top = compute_IFD_mul(place_all_top, cut_off)\n",
    "    IFD_place_x_y = compute_IFD_mul(place_x_y, cut_off)\n",
    "\n",
    "    if IFD_place_all_top >= IFD_place_x_y:\n",
    "        return [num_rel_u,0], IFD_place_all_top\n",
    "    else:\n",
    "        return [top,bottom], IFD_place_x_y\n",
    "list_dataset = [\n",
    "                \"Amazon-lb\", \n",
    "                \"Lastfm\", \n",
    "                \"QK-video\",\n",
    "                \"ML-10M\", \n",
    "                ]\n",
    "model_name = \"NCL\"\n",
    "\n",
    "list_k = [10]\n",
    "max_k = max(list_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in list_dataset:\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(now)\n",
    "\n",
    "    print(f\"Doing {dataset} - {model_name}\")\n",
    "\n",
    "    try:\n",
    "        with open(f\"{path}/precomputeIFD_{dataset}.pickle\",\"rb\") as f:\n",
    "            found = pickle.load(f)\n",
    "            print(\"found existing precomputed result \")\n",
    "            print(found)\n",
    "    except:\n",
    "        print(f\"Cannot find existing result for {dataset}, proceed with precomputing\")\n",
    "\n",
    "        list_filename = [f for f in os.listdir(best_struct_path) if dataset in f and model_name in f]\n",
    "\n",
    "        assert len(list_filename) == 1\n",
    "\n",
    "        with open(f\"{best_struct_path}/{list_filename[0]}\",\"rb\") as f:\n",
    "            struct = pickle.load(f)\n",
    "            num_items = struct.get(\"data.num_items\") - 1\n",
    "            pos_items = struct.get(\"data.pos_items\")\n",
    "            unique_rel_item = sorted(list(set([pos_items_u.size for pos_items_u in pos_items])))\n",
    "        print(\"List of number of unique relevant items per user\", unique_rel_item)\n",
    "\n",
    "        result = dict()\n",
    "        start_time = time.time()\n",
    "        prev_rel_u = 0\n",
    "        prev_strategy = [1,0] #at least 1 relevant item\n",
    "        for num_rel_u in unique_rel_item:\n",
    "            strategy, score = precompute_max_IFD_mul(max_k, num_items, num_rel_u, prev_rel_u, prev_strategy)\n",
    "            #save strategy\n",
    "            result[num_rel_u] = {\"strategy\": strategy, \"score\": score}\n",
    "            prev_strategy = strategy\n",
    "            prev_rel_u = num_rel_u\n",
    "            # time.sleep(0.100) # add delay\n",
    "            if \"ML\" not in dataset:\n",
    "                print(num_rel_u, strategy, score)\n",
    "\n",
    "        print(\"total time taken: \", time.time() - start_time)\n",
    "        print(result)\n",
    "\n",
    "        #save results\n",
    "        with open(f\"{path}/precomputeIFD_{dataset}.pickle\",\"wb\") as f:\n",
    "            pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 1, 3, 5 (for non-real and non-localisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print(*args, **kwargs):\n",
    "    with open(f\"{path}/log_{dataset}_{k}.txt\", 'a+') as f:\n",
    "        return builtins.print(*args, file=f, **kwargs)\n",
    "\n",
    "list_dataset = [\n",
    "                \"Amazon-lb\", \n",
    "                \"Lastfm\", \n",
    "                \"QK-video\",\n",
    "                \"ML-10M\"\n",
    "]\n",
    "\n",
    "for dataset in list_dataset:\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    list_filename = [f for f in os.listdir(best_struct_path) if dataset in f and model_name in f]\n",
    "\n",
    "    assert len(list_filename) == 1\n",
    "\n",
    "    with open(f\"{best_struct_path}/{list_filename[0]}\",\"rb\") as f:\n",
    "        struct = pickle.load(f)\n",
    "        num_items = struct.get(\"data.num_items\") - 1\n",
    "        pos_items = struct.get(\"data.pos_items\")\n",
    "        unique_rel_item = sorted(list(set([pos_items_u.size for pos_items_u in pos_items])))\n",
    "\n",
    "    result = dict()\n",
    "    for k in [1, 3, 5]:\n",
    "        prev_rel_u = 0\n",
    "        prev_strategy = [1,0] #at least 1 relevant item\n",
    "\n",
    "        print(now)\n",
    "        print(f\"Doing {dataset} - {k}\")\n",
    "\n",
    "        try: \n",
    "            with open(f\"{path}/precomputeIFD_{dataset}_{k}.pickle\",\"rb\") as f:\n",
    "                found = pickle.load(f)\n",
    "                print(\"found existing precomputed result \")\n",
    "                print(found)\n",
    "        except:\n",
    "            print(f\"Cannot find existing result for {dataset}, k={k}, proceed with precomputing\")    \n",
    "            start_time = time.time()\n",
    "            for num_rel_u in unique_rel_item:\n",
    "                strategy, score = precompute_max_IFD_mul(k, num_items, num_rel_u, prev_rel_u, prev_strategy)\n",
    "                #save strategy\n",
    "                result[num_rel_u] = {\"strategy\": strategy, \"score\": score}\n",
    "                prev_strategy = strategy\n",
    "                prev_rel_u = num_rel_u\n",
    "\n",
    "            print(\"total time taken: \", time.time() - start_time)\n",
    "            print(result)\n",
    "\n",
    "            #save results\n",
    "            with open(f\"{path}/precomputeIFD_{dataset}_{k}.pickle\",\"wb\") as f:\n",
    "                pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"artificial\"\n",
    "num_items = 10000\n",
    "unique_rel_item = [10]\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def print(*args, **kwargs):\n",
    "    with open(f\"{path}/log_{dataset}.txt\", 'a+') as f:\n",
    "        return builtins.print(*args, file=f, **kwargs)\n",
    "\n",
    "print(now)\n",
    "\n",
    "print(f\"Doing {dataset}\")\n",
    "\n",
    "try:\n",
    "    with open(f\"{path}/precomputeIFD_{dataset}.pickle\",\"rb\") as f:\n",
    "        found = pickle.load(f)\n",
    "        print(\"found existing precomputed result \")\n",
    "        print(found)\n",
    "except:\n",
    "    print(f\"Cannot find existing result for {dataset}, proceed with precomputing\")\n",
    "\n",
    "\n",
    "    print(\"List of number of unique relevant items per user\", unique_rel_item)\n",
    "\n",
    "    result = dict()\n",
    "    start_time = time.time()\n",
    "    prev_rel_u = 0\n",
    "    prev_strategy = [1,0] #at least 1 relevant item\n",
    "    for num_rel_u in unique_rel_item:\n",
    "        strategy, score = precompute_max_IFD_mul(max_k, num_items, num_rel_u, prev_rel_u, prev_strategy)\n",
    "        #save strategy\n",
    "        result[num_rel_u] = {\"strategy\": strategy, \"score\": score}\n",
    "        prev_strategy = strategy\n",
    "        prev_rel_u = num_rel_u\n",
    "        if \"ML\" not in dataset:\n",
    "            print(num_rel_u, strategy, score)\n",
    "\n",
    "    print(\"total time taken: \", time.time() - start_time)\n",
    "    print(result)\n",
    "\n",
    "    #save results\n",
    "    with open(f\"{path}/precomputeIFD_{dataset}.pickle\",\"wb\") as f:\n",
    "        pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many users have only 1 relevant item in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Amazon-lb - NCL\n",
      "104\n",
      "Doing Lastfm - NCL\n",
      "21\n",
      "Doing QK-video - NCL\n",
      "1320\n",
      "Doing ML-10M - NCL\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "from collections import Counter\n",
    "best_struct_path = \"../cluster/best_struct\"\n",
    "list_dataset = [\n",
    "                \"Amazon-lb\", \n",
    "                \"Lastfm\", \n",
    "                \"QK-video\",\n",
    "                \"ML-10M\", \n",
    "                ]\n",
    "model_name = \"NCL\"\n",
    "\n",
    "list_k = [10]\n",
    "max_k = max(list_k)\n",
    "\n",
    "for dataset in list_dataset:\n",
    "    print(f\"Doing {dataset} - {model_name}\")\n",
    "\n",
    "    list_filename = [f for f in os.listdir(best_struct_path) if dataset in f and model_name in f]\n",
    "\n",
    "    assert len(list_filename) == 1\n",
    "\n",
    "    with open(f\"{best_struct_path}/{list_filename[0]}\",\"rb\") as f:\n",
    "        struct = pickle.load(f)\n",
    "        pos_items = struct.get(\"data.pos_items\")\n",
    "        unique_rel_item = Counter([pos_items_u.size for pos_items_u in pos_items])\n",
    "    print(unique_rel_item[1]) #num users with 1 rel item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustextend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
